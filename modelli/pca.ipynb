{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 02:23:53.406631: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-27 02:23:53.432700: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-27 02:23:53.432721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-27 02:23:53.432726: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-27 02:23:53.437385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8108 files belonging to 1 classes.\n",
      "Using 6487 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 02:23:54.796550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.815345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.815487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.925154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.925295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.925378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.978681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.978803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.978890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-27 02:23:54.978953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5799 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8108 files belonging to 1 classes.\n",
      "Using 1621 files for validation.\n",
      "1621   1621\n",
      "got another batch,  0  remaning  we are using  1621\n",
      "6487   6487\n",
      "got another batch,  0  remaning  we are using  6487\n"
     ]
    }
   ],
   "source": [
    "from numpy import size\n",
    "import gc\n",
    "import random as random\n",
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "import tensorflow as tf\n",
    "from scripts import commonUtils as alex\n",
    "\n",
    "# Allow memory growth for the GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "seed=random.randint(1,99999)\n",
    "size=(100,100)\n",
    "dataPath='images100'\n",
    "pool=alex.getSamples(dataPath,size,batchSize=99999,seed=seed,split=0.2)\n",
    "tf.keras.backend.clear_session()\n",
    "poolValidation=alex.getSamples(dataPath,batchSize=9999,imgSize=size,seed=seed,training=False,split=0.2)\n",
    "\n",
    "poolValidation.restPool()\n",
    "valPool=poolValidation.getBatch(reshae=False)\n",
    "batch=pool.getBatch(reshae=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0: shape (6487, 100, 100, 1)\n",
      "Array 1: shape (6487, 100, 100, 1)\n",
      "Array 2: shape (6487, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "split_arrays = np.split(batch, 3, axis=-1)\n",
    "split_arraysVal=np.split(valPool, 3, axis=-1)\n",
    "for i, arr in enumerate(split_arrays):\n",
    "    print(f\"Array {i}: shape {arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(tf.keras.models.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(PCA, self).__init__()\n",
    "\n",
    "  \n",
    "    encoderModel=self.encoderCreate()\n",
    "    decoderModel=self.decoderCreate()\n",
    "    self.encoder = tf.keras.Model(encoderModel[0],encoderModel[1])\n",
    "    self.decoder = tf.keras.Model(decoderModel[0],decoderModel[1])\n",
    "  \n",
    "  def encoderCreate(self):\n",
    "    inputLayer=tf.keras.layers.Input(shape=(100, 100, 1))\n",
    "    conv=tf.keras.layers.Conv2D(5,(3,3),activation='relu', padding='same', strides=2)(inputLayer)\n",
    "    conv2=tf.keras.layers.Conv2D(2,(3,3),activation='relu', padding='same', strides=1)(conv)\n",
    "    flattened = tf.keras.layers.Flatten()(conv2)\n",
    "    dense=tf.keras.layers.Dense(50*50,activation=\"sigmoid\")(flattened)\n",
    "    return inputLayer,dense\n",
    " \n",
    "  def decoderCreate(self):\n",
    "    inputLayer=tf.keras.layers.Input(shape=(50*50))\n",
    "    dense=tf.keras.layers.Dense(50*50,activation=\"sigmoid\")(inputLayer)\n",
    "    reshaped = tf.keras.layers.Reshape((50,50,1))(dense)\n",
    "    upscale= tf.keras.layers.Conv2DTranspose(2, (3,3), activation='relu', padding='same', strides=2)(reshaped)\n",
    "    conv1=tf.keras.layers.Conv2D(5,(3,3),activation='relu', padding='same', strides=1)(upscale)\n",
    "    conv2=tf.keras.layers.Conv2D(1,(3,3),activation='sigmoid', padding='same', strides=1)(conv1)\n",
    "    return  inputLayer,conv2\n",
    "  \n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "\n",
    "    return decoded\n",
    "\n",
    "\n",
    "def ssim_loss(y_true,y_pred ):\n",
    "  result=0\n",
    "  for i in range(0,3):\n",
    "      result+=tf.reduce_mean(tf.image.ssim(y_true[:][:][i], y_pred[:][:][i], 1.0))\n",
    "  return 1.0-result/3.0\n",
    "\n",
    "def costum_loss(y_true,y_pred ):\n",
    "  loss=tf.losses.mse(y_true,y_pred)\n",
    "  ssim_cal=ssim_loss(y_true,y_pred)\n",
    "  return loss+ssim_cal*loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 02:24:00.451171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2025-01-27 02:24:01.746965: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d0f3876a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-01-27 02:24:01.746995: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-27 02:24:01.750670: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-27 02:24:01.825205: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 9s 67ms/step - loss: 0.1516 - mse: 0.0835 - ssim_loss: 0.8150 - costum_loss: 0.1516 - val_loss: 0.1460 - val_mse: 0.0808 - val_ssim_loss: 0.8081 - val_costum_loss: 0.1460\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.1345 - mse: 0.0744 - ssim_loss: 0.8098 - costum_loss: 0.1345 - val_loss: 0.1244 - val_mse: 0.0684 - val_ssim_loss: 0.8201 - val_costum_loss: 0.1244\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.1088 - mse: 0.0595 - ssim_loss: 0.8288 - costum_loss: 0.1088 - val_loss: 0.0932 - val_mse: 0.0508 - val_ssim_loss: 0.8361 - val_costum_loss: 0.0932\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0749 - mse: 0.0410 - ssim_loss: 0.8257 - costum_loss: 0.0749 - val_loss: 0.0619 - val_mse: 0.0339 - val_ssim_loss: 0.8263 - val_costum_loss: 0.0619\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0543 - mse: 0.0303 - ssim_loss: 0.7900 - costum_loss: 0.0543 - val_loss: 0.0490 - val_mse: 0.0273 - val_ssim_loss: 0.7915 - val_costum_loss: 0.0490\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0446 - mse: 0.0253 - ssim_loss: 0.7659 - costum_loss: 0.0446 - val_loss: 0.0423 - val_mse: 0.0240 - val_ssim_loss: 0.7628 - val_costum_loss: 0.0423\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.0380 - mse: 0.0221 - ssim_loss: 0.7243 - costum_loss: 0.0380 - val_loss: 0.0386 - val_mse: 0.0222 - val_ssim_loss: 0.7422 - val_costum_loss: 0.0386\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0354 - mse: 0.0207 - ssim_loss: 0.7097 - costum_loss: 0.0354 - val_loss: 0.0340 - val_mse: 0.0198 - val_ssim_loss: 0.7202 - val_costum_loss: 0.0340\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0314 - mse: 0.0186 - ssim_loss: 0.6862 - costum_loss: 0.0314 - val_loss: 0.0314 - val_mse: 0.0184 - val_ssim_loss: 0.7028 - val_costum_loss: 0.0314\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0287 - mse: 0.0172 - ssim_loss: 0.6631 - costum_loss: 0.0287 - val_loss: 0.0291 - val_mse: 0.0173 - val_ssim_loss: 0.6856 - val_costum_loss: 0.0291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f50f4f2ecd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primo=PCA()\n",
    "#tf.keras.utils.plot_model(autoencoderRevamp.decoder, \"multi_input_and_output_model.png\", expand_nested=True,show_shapes=True)\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "primo.compile(optimizer=opt, loss=costum_loss, metrics=['mse',ssim_loss,costum_loss])\n",
    "primo.fit(split_arrays[0], split_arrays[0], # Note!\n",
    "                  epochs=10,\n",
    "                  shuffle=True,\n",
    "                  batch_size=128,\n",
    "                  validation_data=(split_arraysVal[0], split_arraysVal[0]),\n",
    "               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 5s 43ms/step - loss: 0.1214 - mse: 0.0669 - ssim_loss: 0.8150 - costum_loss: 0.1214 - val_loss: 0.1073 - val_mse: 0.0590 - val_ssim_loss: 0.8192 - val_costum_loss: 0.1073\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0960 - mse: 0.0536 - ssim_loss: 0.7921 - costum_loss: 0.0960 - val_loss: 0.0910 - val_mse: 0.0509 - val_ssim_loss: 0.7888 - val_costum_loss: 0.0910\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0802 - mse: 0.0450 - ssim_loss: 0.7828 - costum_loss: 0.0802 - val_loss: 0.0682 - val_mse: 0.0381 - val_ssim_loss: 0.7904 - val_costum_loss: 0.0682\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0607 - mse: 0.0344 - ssim_loss: 0.7639 - costum_loss: 0.0607 - val_loss: 0.0572 - val_mse: 0.0322 - val_ssim_loss: 0.7759 - val_costum_loss: 0.0572\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0538 - mse: 0.0305 - ssim_loss: 0.7634 - costum_loss: 0.0538 - val_loss: 0.0516 - val_mse: 0.0293 - val_ssim_loss: 0.7651 - val_costum_loss: 0.0516\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0485 - mse: 0.0279 - ssim_loss: 0.7350 - costum_loss: 0.0485 - val_loss: 0.0471 - val_mse: 0.0270 - val_ssim_loss: 0.7468 - val_costum_loss: 0.0471\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0460 - mse: 0.0264 - ssim_loss: 0.7385 - costum_loss: 0.0460 - val_loss: 0.0444 - val_mse: 0.0256 - val_ssim_loss: 0.7358 - val_costum_loss: 0.0444\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0419 - mse: 0.0247 - ssim_loss: 0.6973 - costum_loss: 0.0419 - val_loss: 0.0418 - val_mse: 0.0243 - val_ssim_loss: 0.7229 - val_costum_loss: 0.0418\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0401 - mse: 0.0235 - ssim_loss: 0.7069 - costum_loss: 0.0401 - val_loss: 0.0395 - val_mse: 0.0231 - val_ssim_loss: 0.7112 - val_costum_loss: 0.0395\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0375 - mse: 0.0221 - ssim_loss: 0.6956 - costum_loss: 0.0375 - val_loss: 0.0377 - val_mse: 0.0222 - val_ssim_loss: 0.7033 - val_costum_loss: 0.0377\n"
     ]
    }
   ],
   "source": [
    "secondo=PCA()\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "secondo.compile(optimizer=opt, loss=costum_loss, metrics=['mse',ssim_loss,costum_loss])\n",
    "secondo.fit(split_arrays[1], split_arrays[1], # Note!\n",
    "                  epochs=10,\n",
    "                  shuffle=True,\n",
    "                  batch_size=128,\n",
    "                  validation_data=(split_arraysVal[1], split_arraysVal[1]),\n",
    "               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "51/51 [==============================] - 5s 46ms/step - loss: 0.1603 - mse: 0.0847 - ssim_loss: 0.8942 - costum_loss: 0.1603 - val_loss: 0.1301 - val_mse: 0.0682 - val_ssim_loss: 0.9064 - val_costum_loss: 0.1301\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.1264 - mse: 0.0671 - ssim_loss: 0.8829 - costum_loss: 0.1264 - val_loss: 0.1231 - val_mse: 0.0656 - val_ssim_loss: 0.8767 - val_costum_loss: 0.1231\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.1214 - mse: 0.0651 - ssim_loss: 0.8630 - costum_loss: 0.1214 - val_loss: 0.1174 - val_mse: 0.0631 - val_ssim_loss: 0.8622 - val_costum_loss: 0.1174\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.1116 - mse: 0.0603 - ssim_loss: 0.8494 - costum_loss: 0.1116 - val_loss: 0.1012 - val_mse: 0.0548 - val_ssim_loss: 0.8473 - val_costum_loss: 0.1012\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0818 - mse: 0.0452 - ssim_loss: 0.8073 - costum_loss: 0.0818 - val_loss: 0.0688 - val_mse: 0.0380 - val_ssim_loss: 0.8125 - val_costum_loss: 0.0688\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0634 - mse: 0.0352 - ssim_loss: 0.7977 - costum_loss: 0.0634 - val_loss: 0.0593 - val_mse: 0.0331 - val_ssim_loss: 0.7921 - val_costum_loss: 0.0593\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0572 - mse: 0.0321 - ssim_loss: 0.7820 - costum_loss: 0.0572 - val_loss: 0.0551 - val_mse: 0.0311 - val_ssim_loss: 0.7764 - val_costum_loss: 0.0551\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0537 - mse: 0.0302 - ssim_loss: 0.7768 - costum_loss: 0.0537 - val_loss: 0.0517 - val_mse: 0.0292 - val_ssim_loss: 0.7694 - val_costum_loss: 0.0517\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0502 - mse: 0.0286 - ssim_loss: 0.7536 - costum_loss: 0.0502 - val_loss: 0.0493 - val_mse: 0.0280 - val_ssim_loss: 0.7576 - val_costum_loss: 0.0493\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 0.0475 - mse: 0.0273 - ssim_loss: 0.7400 - costum_loss: 0.0475 - val_loss: 0.0466 - val_mse: 0.0267 - val_ssim_loss: 0.7471 - val_costum_loss: 0.0466\n"
     ]
    }
   ],
   "source": [
    "terzo=PCA()\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "terzo.compile(optimizer=opt, loss=costum_loss, metrics=['mse',ssim_loss,costum_loss])\n",
    "terzo.fit(split_arrays[2], split_arrays[2], # Note!\n",
    "                  epochs=10,\n",
    "                  shuffle=True,\n",
    "                  batch_size=128,\n",
    "                  validation_data=(split_arraysVal[2], split_arraysVal[2]),\n",
    "               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self,a,b,c):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.a=tf.keras.models.clone_model(a)\n",
    "    self.b=tf.keras.models.clone_model(b)\n",
    "    self.c=tf.keras.models.clone_model(c)\n",
    "    encoderModel=self.encoderCreate()\n",
    "    decoderModel=self.decoderCreate()\n",
    "    self.encoder = tf.keras.Model(encoderModel[0],encoderModel[1])\n",
    "    self.decoder = tf.keras.Model(decoderModel[0],decoderModel[1])\n",
    "  \n",
    "  def encoderCreate(self):\n",
    "    inputLayer=tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "    channel_1 = tf.keras.layers.Lambda(lambda x: x[..., 0:1], name=\"channel_1\")(inputLayer)  # Shape: (None, 100, 100, 1)\n",
    "    channel_2 = tf.keras.layers.Lambda(lambda x: x[..., 1:2], name=\"channel_2\")(inputLayer)  # Shape: (None, 100, 100, 1)\n",
    "    channel_3 = tf.keras.layers.Lambda(lambda x: x[..., 2:3], name=\"channel_3\")(inputLayer)  # Shape: (None, 100, 100, 1)\n",
    "    resA=self.a.encoder(channel_1)\n",
    "    resB=self.b.encoder(channel_2)\n",
    "    resC=self.b.encoder(channel_3)\n",
    "    concatenated_output = tf.keras.layers.Concatenate(axis=-1, name=\"concatenated_output\")(\n",
    "        [resA, resB, resC]\n",
    "    )\n",
    "    return inputLayer,concatenated_output\n",
    " \n",
    "  def decoderCreate(self):\n",
    "    inputLayer=tf.keras.layers.Input(shape=(50*50*3))\n",
    "    res=tf.keras.layers.Reshape((50*50,3))(inputLayer)\n",
    "    channel_1 = tf.keras.layers.Lambda(lambda x: x[..., 0:1], name=\"channel_1\")(res)  # Shape: (None, 100, 100, 1)\n",
    "    channel_2 = tf.keras.layers.Lambda(lambda x: x[..., 1:2], name=\"channel_2\")(res)  # Shape: (None, 100, 100, 1)\n",
    "    channel_3 = tf.keras.layers.Lambda(lambda x: x[..., 2:3], name=\"channel_3\")(res)  # Shape: (None, 100, 100, 1)\n",
    "    resA=self.a.decoder(channel_1)\n",
    "    resB=self.b.decoder(channel_2)\n",
    "    resC=self.b.decoder(channel_3)\n",
    "    concatenated_output = tf.keras.layers.Concatenate(axis=-1, name=\"concatenated_output\")(\n",
    "        [resA, resB, resC]\n",
    "    )\n",
    "    return  inputLayer,concatenated_output\n",
    " \n",
    "\n",
    "  def call(self, inputs):\n",
    "    encoded = self.encoder(inputs)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.31163484]\n",
      "  [0.27632046]\n",
      "  [0.37652445]\n",
      "  ...\n",
      "  [0.22926748]\n",
      "  [0.26631057]\n",
      "  [0.349089  ]]\n",
      "\n",
      " [[0.33756664]\n",
      "  [0.28026652]\n",
      "  [0.39816973]\n",
      "  ...\n",
      "  [0.29477805]\n",
      "  [0.35898048]\n",
      "  [0.3240205 ]]\n",
      "\n",
      " [[0.3042416 ]\n",
      "  [0.27625445]\n",
      "  [0.38448375]\n",
      "  ...\n",
      "  [0.21437399]\n",
      "  [0.2660388 ]\n",
      "  [0.37596902]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.30242988]\n",
      "  [0.15409774]\n",
      "  [0.18486167]\n",
      "  ...\n",
      "  [0.13924296]\n",
      "  [0.1826684 ]\n",
      "  [0.3605876 ]]\n",
      "\n",
      " [[0.35725597]\n",
      "  [0.22855563]\n",
      "  [0.20902945]\n",
      "  ...\n",
      "  [0.11854735]\n",
      "  [0.13671668]\n",
      "  [0.2552229 ]]\n",
      "\n",
      " [[0.38214198]\n",
      "  [0.2965852 ]\n",
      "  [0.3024917 ]\n",
      "  ...\n",
      "  [0.22384237]\n",
      "  [0.22052974]\n",
      "  [0.35553208]]], shape=(100, 100, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 02:29:16.390581: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:111 : INVALID_ARGUMENT: slice index 10 of dimension 0 out of bounds.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 10 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m decoder\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecoder(a)\n\u001b[1;32m      8\u001b[0m process_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: (np\u001b[38;5;241m.\u001b[39mclip(x,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m----> 9\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(process_array(decoder[\u001b[38;5;241m10\u001b[39m]))\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlCorso/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/mlCorso/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 10 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "aa=primo.encoder(split_arrays[0][0:100])\n",
    "bb=primo.decoder(aa)\n",
    "print(bb[0])\n",
    "model=MyModel(primo,secondo,terzo)\n",
    "a= model.encoder(valPool[0:10])\n",
    "decoder=model.decoder(a)\n",
    "process_array = lambda x: (np.clip(x,0.0,1.0) * 255).astype(np.uint8)\n",
    "Image.fromarray(process_array(decoder[10])).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
